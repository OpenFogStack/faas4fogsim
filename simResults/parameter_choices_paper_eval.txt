Experiment 1: Effect of processing prices on placement and latency

* Setup:
    - duration 2min = 120000
    - one edge, one intermediary + cloud

* Storage parameters chosen so that all nodes can store all executables

* variance set to 50%

* avg. latency:
    - execution: 30ms
    - edge to intermediary: 20ms
    - intermediary to cloud: 40ms

* prices:
    - storage: irrelevant
    - execution: 100 (to get nice numbers)

* processing capabilities:
    - edge: 5 in parallel
    - intermediary: 20 in parallel

* request arrival:
    - edge can handle max 1000*5/30 = 166 req/s
    - intermediary can handle max edge*4 = 666
    - <166 handled at edge only, < 832 handled at edge and intermediary, > 832 cloud is involved
    - values for requestsPerEdgePerSecond: 100 to 2000 in steps of 100

    val randomSeed = 0L

        /**must be in [0;100]*/
        val maxDevInPercent = 50
        val simulationDuration = 120000
        // params for nodes
        val storageCapacityEdge = 200
        val storageCapacityIntermediary = 1000
        val parallelRequestCapacityEdge = 5
        val parallelRequestCapacityIntermediary = 20

        val avgExecLatency = 30
        val avgEdge2IntermediaryLatency = 20
        val avgIntermediary2CloudLatency = 40
        // params for executables
        val numberOfExecutables = 10
        val averageStoragePrice = 10.0
        val averageExecutableSize = 2
        //params for requests
        var requestsPerEdgePerSecond = 100
        val avgExecutionPrice = 100.0

        //output will be stored as outFileName.csv
        val outFileName = "results_reqsPerSec=$requestsPerEdgePerSecond"
        val logDetails = true




Experiment 2: Effect of storage prices on placement and latency

    * Setup:
        - duration 2min = 120000
        - one edge, one intermediary + cloud

    * Storage:
        - capacity edge: 100
        - capacity intermediary: 500
        - avg executable size: 10
        - varying number of executables from 5 (all fit in edge) to 50 (on avg 20% on edge and all on intermediary) to 100 in steps of 5

    * variance set to 50%

    * avg. latency:
        - execution: 30ms
        - edge to intermediary: 20ms
        - intermediary to cloud: 40ms

    * prices:
        - storage: 100 (to get nice numbers)
        - execution: irrelevant

    * processing:
        - edge & intermediary: 10000 in parallel (should not be limit)
        - requestsPerEdgePerSecond: 10000 (to have enough requests)
